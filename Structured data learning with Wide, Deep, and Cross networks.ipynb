{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2c1d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a42c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (581012, 55)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1   2    3    4     5    6    7    8     9   ...  45  46  47  48  \\\n",
       "0  2596   51   3  258    0   510  221  232  148  6279  ...   0   0   0   0   \n",
       "1  2590   56   2  212   -6   390  220  235  151  6225  ...   0   0   0   0   \n",
       "2  2804  139   9  268   65  3180  234  238  135  6121  ...   0   0   0   0   \n",
       "3  2785  155  18  242  118  3090  238  238  122  6211  ...   0   0   0   0   \n",
       "4  2595   45   2  153   -1   391  220  234  150  6172  ...   0   0   0   0   \n",
       "\n",
       "   49  50  51  52  53  54  \n",
       "0   0   0   0   0   0   5  \n",
       "1   0   0   0   0   0   5  \n",
       "2   0   0   0   0   0   2  \n",
       "3   0   0   0   0   0   2  \n",
       "4   0   0   0   0   0   5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_url = (\n",
    "    \"https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\"\n",
    ")\n",
    "raw_data = pd.read_csv(data_url, header=None)\n",
    "print(f\"Dataset shape: {raw_data.shape}\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df2dfa0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (581012, 13)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Elevation</th>\n",
       "      <td>2596</td>\n",
       "      <td>2590</td>\n",
       "      <td>2804</td>\n",
       "      <td>2785</td>\n",
       "      <td>2595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aspect</th>\n",
       "      <td>51</td>\n",
       "      <td>56</td>\n",
       "      <td>139</td>\n",
       "      <td>155</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Slope</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <td>258</td>\n",
       "      <td>212</td>\n",
       "      <td>268</td>\n",
       "      <td>242</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <td>0</td>\n",
       "      <td>-6</td>\n",
       "      <td>65</td>\n",
       "      <td>118</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <td>510</td>\n",
       "      <td>390</td>\n",
       "      <td>3180</td>\n",
       "      <td>3090</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <td>221</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <td>232</td>\n",
       "      <td>235</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <td>148</td>\n",
       "      <td>151</td>\n",
       "      <td>135</td>\n",
       "      <td>122</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <td>6279</td>\n",
       "      <td>6225</td>\n",
       "      <td>6121</td>\n",
       "      <td>6211</td>\n",
       "      <td>6172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wilderness_Area</th>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "      <td>area_type_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Soil_Type</th>\n",
       "      <td>soil_type_29</td>\n",
       "      <td>soil_type_29</td>\n",
       "      <td>soil_type_12</td>\n",
       "      <td>soil_type_30</td>\n",
       "      <td>soil_type_29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Cover_Type</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               0             1             2  \\\n",
       "Elevation                                   2596          2590          2804   \n",
       "Aspect                                        51            56           139   \n",
       "Slope                                          3             2             9   \n",
       "Horizontal_Distance_To_Hydrology             258           212           268   \n",
       "Vertical_Distance_To_Hydrology                 0            -6            65   \n",
       "Horizontal_Distance_To_Roadways              510           390          3180   \n",
       "Hillshade_9am                                221           220           234   \n",
       "Hillshade_Noon                               232           235           238   \n",
       "Hillshade_3pm                                148           151           135   \n",
       "Horizontal_Distance_To_Fire_Points          6279          6225          6121   \n",
       "Wilderness_Area                      area_type_1   area_type_1   area_type_1   \n",
       "Soil_Type                           soil_type_29  soil_type_29  soil_type_12   \n",
       "Cover_Type                                     4             4             1   \n",
       "\n",
       "                                               3             4  \n",
       "Elevation                                   2785          2595  \n",
       "Aspect                                       155            45  \n",
       "Slope                                         18             2  \n",
       "Horizontal_Distance_To_Hydrology             242           153  \n",
       "Vertical_Distance_To_Hydrology               118            -1  \n",
       "Horizontal_Distance_To_Roadways             3090           391  \n",
       "Hillshade_9am                                238           220  \n",
       "Hillshade_Noon                               238           234  \n",
       "Hillshade_3pm                                122           150  \n",
       "Horizontal_Distance_To_Fire_Points          6211          6172  \n",
       "Wilderness_Area                      area_type_1   area_type_1  \n",
       "Soil_Type                           soil_type_30  soil_type_29  \n",
       "Cover_Type                                     1             4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soil_type_values = [f\"soil_type_{idx+1}\" for idx in range(40)]\n",
    "wilderness_area_values = [f\"area_type_{idx+1}\" for idx in range(4)]\n",
    "\n",
    "soil_type = raw_data.loc[:, 14:53].apply(\n",
    "    lambda x: soil_type_values[0::1][x.to_numpy().nonzero()[0][0]], axis=1\n",
    ")\n",
    "wilderness_area = raw_data.loc[:, 10:13].apply(\n",
    "    lambda x: wilderness_area_values[0::1][x.to_numpy().nonzero()[0][0]], axis=1\n",
    ")\n",
    "\n",
    "CSV_HEADER = [\n",
    "    \"Elevation\",\n",
    "    \"Aspect\",\n",
    "    \"Slope\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Wilderness_Area\",\n",
    "    \"Soil_Type\",\n",
    "    \"Cover_Type\",\n",
    "]\n",
    "\n",
    "data = pd.concat(\n",
    "    [raw_data.loc[:, 0:9], wilderness_area, soil_type, raw_data.loc[:, 54]],\n",
    "    axis=1,\n",
    "    ignore_index=True,\n",
    ")\n",
    "data.columns = CSV_HEADER\n",
    "\n",
    "# Convert the target label indices into a range from 0 to 6 (there are 7 labels in total).\n",
    "data[\"Cover_Type\"] = data[\"Cover_Type\"] - 1\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f90b9c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train split size: 494339\n",
      "Test split size: 86673\n"
     ]
    }
   ],
   "source": [
    "train_splits = []\n",
    "test_splits = []\n",
    "\n",
    "for _, group_data in data.groupby(\"Cover_Type\"):\n",
    "    random_selection = np.random.rand(len(group_data.index)) <= 0.85\n",
    "    train_splits.append(group_data[random_selection])\n",
    "    test_splits.append(group_data[~random_selection])\n",
    "\n",
    "train_data = pd.concat(train_splits).sample(frac=1).reset_index(drop=True)\n",
    "test_data = pd.concat(test_splits).sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(f\"Train split size: {len(train_data.index)}\")\n",
    "print(f\"Test split size: {len(test_data.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6042145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"train_data.csv\"\n",
    "test_data_file = \"test_data.csv\"\n",
    "\n",
    "train_data.to_csv(train_data_file, index=False)\n",
    "test_data.to_csv(test_data_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e146f7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_FEATURE_NAME = \"Cover_Type\"\n",
    "\n",
    "TARGET_FEATURE_LABELS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\"]\n",
    "\n",
    "NUMERIC_FEATURE_NAMES = [\n",
    "    \"Aspect\",\n",
    "    \"Elevation\",\n",
    "    \"Hillshade_3pm\",\n",
    "    \"Hillshade_9am\",\n",
    "    \"Hillshade_Noon\",\n",
    "    \"Horizontal_Distance_To_Fire_Points\",\n",
    "    \"Horizontal_Distance_To_Hydrology\",\n",
    "    \"Horizontal_Distance_To_Roadways\",\n",
    "    \"Slope\",\n",
    "    \"Vertical_Distance_To_Hydrology\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES_WITH_VOCABULARY = {\n",
    "    \"Soil_Type\": list(data[\"Soil_Type\"].unique()),\n",
    "    \"Wilderness_Area\": list(data[\"Wilderness_Area\"].unique()),\n",
    "}\n",
    "\n",
    "CATEGORICAL_FEATURE_NAMES = list(CATEGORICAL_FEATURES_WITH_VOCABULARY.keys())\n",
    "\n",
    "FEATURE_NAMES = NUMERIC_FEATURE_NAMES + CATEGORICAL_FEATURE_NAMES\n",
    "\n",
    "COLUMN_DEFAULTS = [\n",
    "    [0] if feature_name in NUMERIC_FEATURE_NAMES + [TARGET_FEATURE_NAME] else [\"NA\"]\n",
    "    for feature_name in CSV_HEADER\n",
    "]\n",
    "\n",
    "NUM_CLASSES = len(TARGET_FEATURE_LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7be1dda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_from_csv(csv_file_path, batch_size, shuffle=False):\n",
    "\n",
    "    dataset = tf.data.experimental.make_csv_dataset(\n",
    "        csv_file_path,\n",
    "        batch_size=batch_size,\n",
    "        column_names=CSV_HEADER,\n",
    "        column_defaults=COLUMN_DEFAULTS,\n",
    "        label_name=TARGET_FEATURE_NAME,\n",
    "        num_epochs=1,\n",
    "        header=True,\n",
    "        shuffle=shuffle,\n",
    "    )\n",
    "    return dataset.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6918e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "dropout_rate = 0.1\n",
    "batch_size = 265\n",
    "num_epochs = 50\n",
    "\n",
    "hidden_units = [32, 32]\n",
    "\n",
    "\n",
    "def run_experiment(model):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "        metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    train_dataset = get_dataset_from_csv(train_data_file, batch_size, shuffle=True)\n",
    "\n",
    "    test_dataset = get_dataset_from_csv(test_data_file, batch_size)\n",
    "\n",
    "    print(\"Start training the model...\")\n",
    "    history = model.fit(train_dataset, epochs=num_epochs)\n",
    "    print(\"Model training finished\")\n",
    "\n",
    "    _, accuracy = model.evaluate(test_dataset, verbose=0)\n",
    "\n",
    "    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2e11a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_inputs():\n",
    "    inputs = {}\n",
    "    for feature_name in FEATURE_NAMES:\n",
    "        if feature_name in NUMERIC_FEATURE_NAMES:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.float32\n",
    "            )\n",
    "        else:\n",
    "            inputs[feature_name] = layers.Input(\n",
    "                name=feature_name, shape=(), dtype=tf.string\n",
    "            )\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a82a23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import StringLookup\n",
    "\n",
    "\n",
    "def encode_inputs(inputs, use_embedding=False):\n",
    "    encoded_features = []\n",
    "    for feature_name in inputs:\n",
    "        if feature_name in CATEGORICAL_FEATURE_NAMES:\n",
    "            vocabulary = CATEGORICAL_FEATURES_WITH_VOCABULARY[feature_name]\n",
    "            # Create a lookup to convert string values to an integer indices.\n",
    "            # Since we are not using a mask token nor expecting any out of vocabulary\n",
    "            # (oov) token, we set mask_token to None and  num_oov_indices to 0.\n",
    "            lookup = StringLookup(\n",
    "                vocabulary=vocabulary,\n",
    "                mask_token=None,\n",
    "                num_oov_indices=0,\n",
    "                output_mode=\"int\" if use_embedding else \"binary\",\n",
    "            )\n",
    "            if use_embedding:\n",
    "                # Convert the string input values into integer indices.\n",
    "                encoded_feature = lookup(inputs[feature_name])\n",
    "                embedding_dims = int(math.sqrt(len(vocabulary)))\n",
    "                # Create an embedding layer with the specified dimensions.\n",
    "                embedding = layers.Embedding(\n",
    "                    input_dim=len(vocabulary), output_dim=embedding_dims\n",
    "                )\n",
    "                # Convert the index values to embedding representations.\n",
    "                encoded_feature = embedding(encoded_feature)\n",
    "            else:\n",
    "                # Convert the string input values into a one hot encoding.\n",
    "                encoded_feature = lookup(tf.expand_dims(inputs[feature_name], -1))\n",
    "        else:\n",
    "            # Use the numerical features as-is.\n",
    "            encoded_feature = tf.expand_dims(inputs[feature_name], -1)\n",
    "\n",
    "        encoded_features.append(encoded_feature)\n",
    "\n",
    "    all_features = layers.concatenate(encoded_features)\n",
    "    return all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc17a7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Setup Game\\Desktop\\Chat-Voice bots\\NeuralNet_venv\\lib\\site-packages\\numpy\\core\\numeric.py:2463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    }
   ],
   "source": [
    "def create_baseline_model():\n",
    "    inputs = create_model_inputs()\n",
    "    features = encode_inputs(inputs)\n",
    "\n",
    "    for units in hidden_units:\n",
    "        features = layers.Dense(units)(features)\n",
    "        features = layers.BatchNormalization()(features)\n",
    "        features = layers.ReLU()(features)\n",
    "        features = layers.Dropout(dropout_rate)(features)\n",
    "\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "baseline_model = create_baseline_model()\n",
    "keras.utils.plot_model(baseline_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c247d6e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "1866/1866 [==============================] - 10s 5ms/step - loss: 0.7820 - sparse_categorical_accuracy: 0.6783\n",
      "Epoch 2/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.6672 - sparse_categorical_accuracy: 0.7145\n",
      "Epoch 3/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.6415 - sparse_categorical_accuracy: 0.7256\n",
      "Epoch 4/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.6226 - sparse_categorical_accuracy: 0.7330\n",
      "Epoch 5/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.6102 - sparse_categorical_accuracy: 0.7382\n",
      "Epoch 6/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.6019 - sparse_categorical_accuracy: 0.7415\n",
      "Epoch 7/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5952 - sparse_categorical_accuracy: 0.7444\n",
      "Epoch 8/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5902 - sparse_categorical_accuracy: 0.7462\n",
      "Epoch 9/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5848 - sparse_categorical_accuracy: 0.7488\n",
      "Epoch 10/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5803 - sparse_categorical_accuracy: 0.7505\n",
      "Epoch 11/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5772 - sparse_categorical_accuracy: 0.7520\n",
      "Epoch 12/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5736 - sparse_categorical_accuracy: 0.7536\n",
      "Epoch 13/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5711 - sparse_categorical_accuracy: 0.7544\n",
      "Epoch 14/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5684 - sparse_categorical_accuracy: 0.7558\n",
      "Epoch 15/50\n",
      "1866/1866 [==============================] - 4s 2ms/step - loss: 0.5661 - sparse_categorical_accuracy: 0.7567\n",
      "Epoch 16/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5646 - sparse_categorical_accuracy: 0.7576\n",
      "Epoch 17/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5624 - sparse_categorical_accuracy: 0.7577\n",
      "Epoch 18/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5603 - sparse_categorical_accuracy: 0.7595\n",
      "Epoch 19/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5586 - sparse_categorical_accuracy: 0.7597\n",
      "Epoch 20/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5572 - sparse_categorical_accuracy: 0.7607\n",
      "Epoch 21/50\n",
      "1866/1866 [==============================] - 6s 3ms/step - loss: 0.5551 - sparse_categorical_accuracy: 0.7615\n",
      "Epoch 22/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5541 - sparse_categorical_accuracy: 0.7624\n",
      "Epoch 23/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5521 - sparse_categorical_accuracy: 0.7632\n",
      "Epoch 24/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5498 - sparse_categorical_accuracy: 0.7641\n",
      "Epoch 25/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5495 - sparse_categorical_accuracy: 0.7644\n",
      "Epoch 26/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5478 - sparse_categorical_accuracy: 0.7649\n",
      "Epoch 27/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5472 - sparse_categorical_accuracy: 0.7649\n",
      "Epoch 28/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5453 - sparse_categorical_accuracy: 0.7662\n",
      "Epoch 29/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5445 - sparse_categorical_accuracy: 0.7667\n",
      "Epoch 30/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5438 - sparse_categorical_accuracy: 0.7668\n",
      "Epoch 31/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5434 - sparse_categorical_accuracy: 0.7667\n",
      "Epoch 32/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5423 - sparse_categorical_accuracy: 0.7675\n",
      "Epoch 33/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5408 - sparse_categorical_accuracy: 0.7679\n",
      "Epoch 34/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5407 - sparse_categorical_accuracy: 0.7678\n",
      "Epoch 35/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5410 - sparse_categorical_accuracy: 0.7677\n",
      "Epoch 36/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5397 - sparse_categorical_accuracy: 0.7681\n",
      "Epoch 37/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5383 - sparse_categorical_accuracy: 0.7691\n",
      "Epoch 38/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5379 - sparse_categorical_accuracy: 0.7692\n",
      "Epoch 39/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5382 - sparse_categorical_accuracy: 0.7692\n",
      "Epoch 40/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5372 - sparse_categorical_accuracy: 0.7692\n",
      "Epoch 41/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5367 - sparse_categorical_accuracy: 0.7700\n",
      "Epoch 42/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5364 - sparse_categorical_accuracy: 0.7698\n",
      "Epoch 43/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5357 - sparse_categorical_accuracy: 0.7697\n",
      "Epoch 44/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5348 - sparse_categorical_accuracy: 0.7708\n",
      "Epoch 45/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5342 - sparse_categorical_accuracy: 0.7704\n",
      "Epoch 46/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5351 - sparse_categorical_accuracy: 0.7705\n",
      "Epoch 47/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5331 - sparse_categorical_accuracy: 0.7709\n",
      "Epoch 48/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5337 - sparse_categorical_accuracy: 0.7709\n",
      "Epoch 49/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5329 - sparse_categorical_accuracy: 0.7716\n",
      "Epoch 50/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5327 - sparse_categorical_accuracy: 0.7714\n",
      "Model training finished\n",
      "Test accuracy: 73.35%\n"
     ]
    }
   ],
   "source": [
    "run_experiment(baseline_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9567d2d5",
   "metadata": {},
   "source": [
    "<h4>Experiment 2: Wide & Deep model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a69f1ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "def create_wide_and_deep_model():\n",
    "\n",
    "    inputs = create_model_inputs()\n",
    "    wide = encode_inputs(inputs)\n",
    "    wide = layers.BatchNormalization()(wide)\n",
    "\n",
    "    deep = encode_inputs(inputs, use_embedding=True)\n",
    "    for units in hidden_units:\n",
    "        deep = layers.Dense(units)(deep)\n",
    "        deep = layers.BatchNormalization()(deep)\n",
    "        deep = layers.ReLU()(deep)\n",
    "        deep = layers.Dropout(dropout_rate)(deep)\n",
    "\n",
    "    merged = layers.concatenate([wide, deep])\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(merged)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "wide_and_deep_model = create_wide_and_deep_model()\n",
    "keras.utils.plot_model(wide_and_deep_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c69f0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "1866/1866 [==============================] - 10s 4ms/step - loss: 0.7034 - sparse_categorical_accuracy: 0.7028\n",
      "Epoch 2/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.6072 - sparse_categorical_accuracy: 0.7366\n",
      "Epoch 3/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5896 - sparse_categorical_accuracy: 0.7435\n",
      "Epoch 4/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5776 - sparse_categorical_accuracy: 0.7482\n",
      "Epoch 5/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5674 - sparse_categorical_accuracy: 0.7528\n",
      "Epoch 6/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5596 - sparse_categorical_accuracy: 0.7579\n",
      "Epoch 7/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5532 - sparse_categorical_accuracy: 0.7610\n",
      "Epoch 8/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5464 - sparse_categorical_accuracy: 0.7648\n",
      "Epoch 9/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5418 - sparse_categorical_accuracy: 0.7673\n",
      "Epoch 10/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5379 - sparse_categorical_accuracy: 0.7693\n",
      "Epoch 11/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5333 - sparse_categorical_accuracy: 0.7715\n",
      "Epoch 12/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5302 - sparse_categorical_accuracy: 0.7729\n",
      "Epoch 13/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5272 - sparse_categorical_accuracy: 0.7739\n",
      "Epoch 14/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5248 - sparse_categorical_accuracy: 0.7756\n",
      "Epoch 15/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5221 - sparse_categorical_accuracy: 0.7772\n",
      "Epoch 16/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5202 - sparse_categorical_accuracy: 0.7780\n",
      "Epoch 17/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5182 - sparse_categorical_accuracy: 0.7793\n",
      "Epoch 18/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5172 - sparse_categorical_accuracy: 0.7798\n",
      "Epoch 19/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5152 - sparse_categorical_accuracy: 0.7812\n",
      "Epoch 20/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5142 - sparse_categorical_accuracy: 0.7814\n",
      "Epoch 21/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5125 - sparse_categorical_accuracy: 0.7819\n",
      "Epoch 22/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5117 - sparse_categorical_accuracy: 0.7830\n",
      "Epoch 23/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5111 - sparse_categorical_accuracy: 0.7832\n",
      "Epoch 24/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5090 - sparse_categorical_accuracy: 0.7841\n",
      "Epoch 25/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5085 - sparse_categorical_accuracy: 0.7847\n",
      "Epoch 26/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5073 - sparse_categorical_accuracy: 0.7843\n",
      "Epoch 27/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5071 - sparse_categorical_accuracy: 0.7849\n",
      "Epoch 28/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5066 - sparse_categorical_accuracy: 0.7852\n",
      "Epoch 29/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5054 - sparse_categorical_accuracy: 0.7859\n",
      "Epoch 30/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5059 - sparse_categorical_accuracy: 0.7852\n",
      "Epoch 31/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5044 - sparse_categorical_accuracy: 0.7859\n",
      "Epoch 32/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5042 - sparse_categorical_accuracy: 0.7862\n",
      "Epoch 33/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5035 - sparse_categorical_accuracy: 0.7866\n",
      "Epoch 34/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5028 - sparse_categorical_accuracy: 0.7874\n",
      "Epoch 35/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5026 - sparse_categorical_accuracy: 0.7868\n",
      "Epoch 36/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5026 - sparse_categorical_accuracy: 0.7869\n",
      "Epoch 37/50\n",
      "1866/1866 [==============================] - 5s 2ms/step - loss: 0.5019 - sparse_categorical_accuracy: 0.7876\n",
      "Epoch 38/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5010 - sparse_categorical_accuracy: 0.7877\n",
      "Epoch 39/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5008 - sparse_categorical_accuracy: 0.7877\n",
      "Epoch 40/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5000 - sparse_categorical_accuracy: 0.7881\n",
      "Epoch 41/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4999 - sparse_categorical_accuracy: 0.7883\n",
      "Epoch 42/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4995 - sparse_categorical_accuracy: 0.7888\n",
      "Epoch 43/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4982 - sparse_categorical_accuracy: 0.7887\n",
      "Epoch 44/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4989 - sparse_categorical_accuracy: 0.7880\n",
      "Epoch 45/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4981 - sparse_categorical_accuracy: 0.7887\n",
      "Epoch 46/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4979 - sparse_categorical_accuracy: 0.7895\n",
      "Epoch 47/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4980 - sparse_categorical_accuracy: 0.7887\n",
      "Epoch 48/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4973 - sparse_categorical_accuracy: 0.7893\n",
      "Epoch 49/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4966 - sparse_categorical_accuracy: 0.7893\n",
      "Epoch 50/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4965 - sparse_categorical_accuracy: 0.7895\n",
      "Model training finished\n",
      "Test accuracy: 80.89%\n"
     ]
    }
   ],
   "source": [
    "run_experiment(wide_and_deep_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d20aa7d",
   "metadata": {},
   "source": [
    "<h4>Experiment 3: Deep & Cross model</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4609e6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "def create_deep_and_cross_model():\n",
    "\n",
    "    inputs = create_model_inputs()\n",
    "    x0 = encode_inputs(inputs, use_embedding=True)\n",
    "\n",
    "    cross = x0\n",
    "    for _ in hidden_units:\n",
    "        units = cross.shape[-1]\n",
    "        x = layers.Dense(units)(cross)\n",
    "        cross = x0 * x + cross\n",
    "    cross = layers.BatchNormalization()(cross)\n",
    "\n",
    "    deep = x0\n",
    "    for units in hidden_units:\n",
    "        deep = layers.Dense(units)(deep)\n",
    "        deep = layers.BatchNormalization()(deep)\n",
    "        deep = layers.ReLU()(deep)\n",
    "        deep = layers.Dropout(dropout_rate)(deep)\n",
    "\n",
    "    merged = layers.concatenate([cross, deep])\n",
    "    outputs = layers.Dense(units=NUM_CLASSES, activation=\"softmax\")(merged)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "deep_and_cross_model = create_deep_and_cross_model()\n",
    "keras.utils.plot_model(deep_and_cross_model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a22e5e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training the model...\n",
      "Epoch 1/50\n",
      "1866/1866 [==============================] - 10s 5ms/step - loss: 0.6902 - sparse_categorical_accuracy: 0.7128\n",
      "Epoch 2/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5928 - sparse_categorical_accuracy: 0.7449\n",
      "Epoch 3/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5721 - sparse_categorical_accuracy: 0.7534\n",
      "Epoch 4/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5608 - sparse_categorical_accuracy: 0.7581\n",
      "Epoch 5/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5526 - sparse_categorical_accuracy: 0.7614\n",
      "Epoch 6/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5467 - sparse_categorical_accuracy: 0.7640\n",
      "Epoch 7/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5415 - sparse_categorical_accuracy: 0.7667\n",
      "Epoch 8/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5378 - sparse_categorical_accuracy: 0.7677\n",
      "Epoch 9/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5347 - sparse_categorical_accuracy: 0.7689\n",
      "Epoch 10/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5318 - sparse_categorical_accuracy: 0.7700\n",
      "Epoch 11/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5298 - sparse_categorical_accuracy: 0.7706\n",
      "Epoch 12/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5272 - sparse_categorical_accuracy: 0.7719\n",
      "Epoch 13/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5255 - sparse_categorical_accuracy: 0.7726\n",
      "Epoch 14/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5241 - sparse_categorical_accuracy: 0.7734\n",
      "Epoch 15/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5223 - sparse_categorical_accuracy: 0.7735\n",
      "Epoch 16/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5206 - sparse_categorical_accuracy: 0.7739\n",
      "Epoch 17/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5188 - sparse_categorical_accuracy: 0.7751\n",
      "Epoch 18/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5172 - sparse_categorical_accuracy: 0.7758\n",
      "Epoch 19/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5165 - sparse_categorical_accuracy: 0.7767\n",
      "Epoch 20/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5147 - sparse_categorical_accuracy: 0.7770\n",
      "Epoch 21/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5135 - sparse_categorical_accuracy: 0.7778\n",
      "Epoch 22/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5116 - sparse_categorical_accuracy: 0.7784\n",
      "Epoch 23/50\n",
      "1866/1866 [==============================] - 6s 3ms/step - loss: 0.5101 - sparse_categorical_accuracy: 0.7787\n",
      "Epoch 24/50\n",
      "1866/1866 [==============================] - 6s 3ms/step - loss: 0.5094 - sparse_categorical_accuracy: 0.7788\n",
      "Epoch 25/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5085 - sparse_categorical_accuracy: 0.7796\n",
      "Epoch 26/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5075 - sparse_categorical_accuracy: 0.7802\n",
      "Epoch 27/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5070 - sparse_categorical_accuracy: 0.7800\n",
      "Epoch 28/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5059 - sparse_categorical_accuracy: 0.7812\n",
      "Epoch 29/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5051 - sparse_categorical_accuracy: 0.7809\n",
      "Epoch 30/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5039 - sparse_categorical_accuracy: 0.7815\n",
      "Epoch 31/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5030 - sparse_categorical_accuracy: 0.7819\n",
      "Epoch 32/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5026 - sparse_categorical_accuracy: 0.7825\n",
      "Epoch 33/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5016 - sparse_categorical_accuracy: 0.7826\n",
      "Epoch 34/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5004 - sparse_categorical_accuracy: 0.7829\n",
      "Epoch 35/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.5006 - sparse_categorical_accuracy: 0.7832\n",
      "Epoch 36/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4993 - sparse_categorical_accuracy: 0.7840\n",
      "Epoch 37/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4983 - sparse_categorical_accuracy: 0.7844\n",
      "Epoch 38/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4976 - sparse_categorical_accuracy: 0.7846\n",
      "Epoch 39/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4965 - sparse_categorical_accuracy: 0.7852\n",
      "Epoch 40/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4958 - sparse_categorical_accuracy: 0.7853\n",
      "Epoch 41/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4951 - sparse_categorical_accuracy: 0.7853\n",
      "Epoch 42/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4938 - sparse_categorical_accuracy: 0.7861\n",
      "Epoch 43/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4937 - sparse_categorical_accuracy: 0.7861\n",
      "Epoch 44/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4933 - sparse_categorical_accuracy: 0.7867\n",
      "Epoch 45/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4924 - sparse_categorical_accuracy: 0.7870\n",
      "Epoch 46/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4920 - sparse_categorical_accuracy: 0.7876\n",
      "Epoch 47/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4913 - sparse_categorical_accuracy: 0.7875\n",
      "Epoch 48/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4906 - sparse_categorical_accuracy: 0.7882\n",
      "Epoch 49/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4901 - sparse_categorical_accuracy: 0.7879\n",
      "Epoch 50/50\n",
      "1866/1866 [==============================] - 5s 3ms/step - loss: 0.4889 - sparse_categorical_accuracy: 0.7881\n",
      "Model training finished\n",
      "Test accuracy: 80.13%\n"
     ]
    }
   ],
   "source": [
    "run_experiment(deep_and_cross_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37df4321",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9087f61",
   "metadata": {},
   "source": [
    "<h6>We import the necessary packages</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10377028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ae319325",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_url = \"http://storage.googleapis.com/download.tensorflow.org/data/heart.csv\"\n",
    "dataframe = pd.read_csv(file_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "401c7e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "34e16e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>fixed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>reversible</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "   ca        thal  target  \n",
       "0   0       fixed       0  \n",
       "1   3      normal       1  \n",
       "2   2  reversible       0  \n",
       "3   0      normal       0  \n",
       "4   0      normal       0  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c44fd4f",
   "metadata": {},
   "source": [
    "<h6>Let's split the data into a training and validation set, where the validation set is 20% of the whole data.\n",
    "then we only remove validation dataset rows by index from the dataframe to make a training set</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "31657436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 242 samples for training and 61 for validation\n"
     ]
    }
   ],
   "source": [
    "val_dataframe = dataframe.sample(frac=0.2, random_state=1337)\n",
    "train_dataframe = dataframe.drop(val_dataframe.index)\n",
    "\n",
    "print(\n",
    "    \"Using %d samples for training and %d for validation\"\n",
    "    % (len(train_dataframe), len(val_dataframe))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c928a8",
   "metadata": {},
   "source": [
    "<h6>Often when working on a deep learning model you will retrieve your source data in a pandas. DataFrame and need to convert it into a format that Tensorflow can read. Fortunately, Tensorflow now has Datasets which create data pipelines for your network to train on. Converting a DataFrame into a tf dataset</h6>\n",
    "\n",
    "<h6>pop function returns item passed in parameter and drop it from the dataframe. </h6>\n",
    "\n",
    "<h6>we can get the slices of an array in the form of objects by using tf.data.Dataset.from_tensor_slices() method.</h6>\n",
    "\n",
    "<h6>The tf.data.Dataset.shuffle() method randomly shuffles a tensor along its first dimension, buffer_size is the number of elements from which the new dataset will be sampled.</h6>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "3770d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataframe_to_dataset(dataframe):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(\"target\")\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    return ds\n",
    "\n",
    "\n",
    "train_ds = dataframe_to_dataset(train_dataframe)\n",
    "val_ds = dataframe_to_dataset(val_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a86509c",
   "metadata": {},
   "source": [
    "<h6>Each Dataset yields a tuple (input, target) where input is a dictionary of features and target is the value 0 or 1:</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7f46da7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: {'age': <tf.Tensor: shape=(), dtype=int64, numpy=62>, 'sex': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'cp': <tf.Tensor: shape=(), dtype=int64, numpy=4>, 'trestbps': <tf.Tensor: shape=(), dtype=int64, numpy=160>, 'chol': <tf.Tensor: shape=(), dtype=int64, numpy=164>, 'fbs': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'restecg': <tf.Tensor: shape=(), dtype=int64, numpy=2>, 'thalach': <tf.Tensor: shape=(), dtype=int64, numpy=145>, 'exang': <tf.Tensor: shape=(), dtype=int64, numpy=0>, 'oldpeak': <tf.Tensor: shape=(), dtype=float64, numpy=6.2>, 'slope': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'ca': <tf.Tensor: shape=(), dtype=int64, numpy=3>, 'thal': <tf.Tensor: shape=(), dtype=string, numpy=b'reversible'>}\n",
      "Target: tf.Tensor(1, shape=(), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_ds.take(1):\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335c62ba",
   "metadata": {},
   "source": [
    "<h6>The tf.data.Dataset.batch() function is used to group the elements into batches, where batchSize is the number elements that should there in a single batch. </h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0e513918",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.batch(32)\n",
    "val_ds = val_ds.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ca9c658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import IntegerLookup\n",
    "from tensorflow.keras.layers import Normalization\n",
    "from tensorflow.keras.layers import StringLookup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af07d5",
   "metadata": {},
   "source": [
    "<h6>forcategorical features encoded as integers, we will encode them using One hot encoding, it is one method of converting data to prepare it for an algorithm and get a better prediction. With one-hot, we convert each categorical value into a new categorical column and assign a binary value of 1 or 0 to those columns. Each integer value is represented as a binary vector. All the values are zero, and the index is marked with a 1.\n",
    "we want a simple solution that will handle out of range inputs at inference, so we will use IntegerLookup().\n",
    "</h6>\n",
    "\n",
    "<h6> We also have a categorical feature encoded as a string, We will create an index of all possible features and encode output using the StringLookup() layer\n",
    "</h6>\n",
    "\n",
    "<h6>Normalization can help training of our neural networks as the different features are on a similar scale, which helps to stabilize the gradient descent step, allowing us to use larger learning rates or help models converge faster for a given learning rate.</h6>\n",
    "\n",
    "<h6>Calling adapt() on a Normalization layer is an alternative to passing in mean and variance arguments during layer construction. A Normalization layer should always either be adapted over a dataset or passed mean and variance .</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f1231b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_numerical_feature(feature, name, dataset):\n",
    "    # Create a Normalization layer for our feature\n",
    "    normalizer = Normalization()\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the statistics of the data\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    # Normalize the input feature\n",
    "    encoded_feature = normalizer(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7d31f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_categorical_feature(feature, name, dataset, is_string):\n",
    "    lookup_class = StringLookup if is_string else IntegerLookup\n",
    "    # Create a lookup layer which will turn strings into integer indices\n",
    "    lookup = lookup_class(output_mode=\"binary\")\n",
    "\n",
    "    # Prepare a Dataset that only yields our feature\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "    feature_ds = feature_ds.map(lambda x: tf.expand_dims(x, -1))\n",
    "\n",
    "    # Learn the set of possible string values and assign them a fixed integer index\n",
    "    lookup.adapt(feature_ds)\n",
    "\n",
    "    # Turn the string input into integer indices\n",
    "    encoded_feature = lookup(feature)\n",
    "    return encoded_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b4942f",
   "metadata": {},
   "source": [
    "<h6>In Keras, the input layer itself is not a layer, but a tensor. It's the starting tensor you send to the first hidden layer.</h6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46504840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features encoded as integers\n",
    "sex = keras.Input(shape=(1,), name=\"sex\", dtype=\"int64\")\n",
    "cp = keras.Input(shape=(1,), name=\"cp\", dtype=\"int64\")\n",
    "fbs = keras.Input(shape=(1,), name=\"fbs\", dtype=\"int64\")\n",
    "restecg = keras.Input(shape=(1,), name=\"restecg\", dtype=\"int64\")\n",
    "exang = keras.Input(shape=(1,), name=\"exang\", dtype=\"int64\")\n",
    "ca = keras.Input(shape=(1,), name=\"ca\", dtype=\"int64\")\n",
    "\n",
    "# Categorical feature encoded as string\n",
    "thal = keras.Input(shape=(1,), name=\"thal\", dtype=\"string\")\n",
    "\n",
    "# Numerical features\n",
    "age = keras.Input(shape=(1,), name=\"age\")\n",
    "trestbps = keras.Input(shape=(1,), name=\"trestbps\")\n",
    "chol = keras.Input(shape=(1,), name=\"chol\")\n",
    "thalach = keras.Input(shape=(1,), name=\"thalach\")\n",
    "oldpeak = keras.Input(shape=(1,), name=\"oldpeak\")\n",
    "slope = keras.Input(shape=(1,), name=\"slope\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff67db",
   "metadata": {},
   "source": [
    "<h6>layers.concatenate, is a function that concatenates a list of inputs. It takes as input a list of tensors, all of the same shape except for the concatenation axis, and returns a single tensor, the concatenation of all inputs.</h6>\n",
    "\n",
    "<h6>A Dense layer feeds all outputs from the previous layer to all its neurons, each neuron providing one output to the next layer.</h6>\n",
    "\n",
    "<h6>Dropout is a technique to reduce overfitting when training the model.The choice of neurons to be deactivated is random. We assign a probability p to all neurons which determines their activation.\n",
    "When p = 0.2, each neuron has 2/10 to be deactivated.</h6>\n",
    "\n",
    "<h6>keras.Model groups layers into an object, where inputs are a list of keras.Input objects and the outputs of the model</h6> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7c16508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = [\n",
    "    sex,\n",
    "    cp,\n",
    "    fbs,\n",
    "    restecg,\n",
    "    exang,\n",
    "    ca,\n",
    "    thal,\n",
    "    age,\n",
    "    trestbps,\n",
    "    chol,\n",
    "    thalach,\n",
    "    oldpeak,\n",
    "    slope,\n",
    "]\n",
    "# Integer categorical features\n",
    "sex_encoded = encode_categorical_feature(sex, \"sex\", train_ds, False)\n",
    "cp_encoded = encode_categorical_feature(cp, \"cp\", train_ds, False)\n",
    "fbs_encoded = encode_categorical_feature(fbs, \"fbs\", train_ds, False)\n",
    "restecg_encoded = encode_categorical_feature(restecg, \"restecg\", train_ds, False)\n",
    "exang_encoded = encode_categorical_feature(exang, \"exang\", train_ds, False)\n",
    "ca_encoded = encode_categorical_feature(ca, \"ca\", train_ds, False)\n",
    "\n",
    "# String categorical features\n",
    "thal_encoded = encode_categorical_feature(thal, \"thal\", train_ds, True)\n",
    "\n",
    "# Numerical features\n",
    "age_encoded = encode_numerical_feature(age, \"age\", train_ds)\n",
    "trestbps_encoded = encode_numerical_feature(trestbps, \"trestbps\", train_ds)\n",
    "chol_encoded = encode_numerical_feature(chol, \"chol\", train_ds)\n",
    "thalach_encoded = encode_numerical_feature(thalach, \"thalach\", train_ds)\n",
    "oldpeak_encoded = encode_numerical_feature(oldpeak, \"oldpeak\", train_ds)\n",
    "slope_encoded = encode_numerical_feature(slope, \"slope\", train_ds)\n",
    "\n",
    "all_features = layers.concatenate(\n",
    "    [\n",
    "        sex_encoded,\n",
    "        cp_encoded,\n",
    "        fbs_encoded,\n",
    "        restecg_encoded,\n",
    "        exang_encoded,\n",
    "        slope_encoded,\n",
    "        ca_encoded,\n",
    "        thal_encoded,\n",
    "        age_encoded,\n",
    "        trestbps_encoded,\n",
    "        chol_encoded,\n",
    "        thalach_encoded,\n",
    "        oldpeak_encoded,\n",
    "    ]\n",
    ")\n",
    "x = layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(all_inputs, output)\n",
    "model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e8b0cade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# `rankdir='LR'` is to make the graph horizontal.\n",
    "keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d1ad645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 1s 34ms/step - loss: 0.8434 - accuracy: 0.3967 - val_loss: 0.8244 - val_accuracy: 0.2459\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7972 - accuracy: 0.4463 - val_loss: 0.7597 - val_accuracy: 0.4262\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7394 - accuracy: 0.5041 - val_loss: 0.7049 - val_accuracy: 0.5902\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.7095 - accuracy: 0.5124 - val_loss: 0.6559 - val_accuracy: 0.6721\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6231 - accuracy: 0.6446 - val_loss: 0.6155 - val_accuracy: 0.7049\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.6736 - val_loss: 0.5809 - val_accuracy: 0.7541\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5664 - accuracy: 0.7273 - val_loss: 0.5510 - val_accuracy: 0.7705\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7686 - val_loss: 0.5249 - val_accuracy: 0.7705\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.7769 - val_loss: 0.5028 - val_accuracy: 0.7705\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7769 - val_loss: 0.4833 - val_accuracy: 0.7869\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.8017 - val_loss: 0.4672 - val_accuracy: 0.7869\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7851 - val_loss: 0.4540 - val_accuracy: 0.7869\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.7851 - val_loss: 0.4429 - val_accuracy: 0.7869\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.7975 - val_loss: 0.4335 - val_accuracy: 0.7869\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4257 - accuracy: 0.8058 - val_loss: 0.4244 - val_accuracy: 0.7869\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.7975 - val_loss: 0.4168 - val_accuracy: 0.7869\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.4145 - accuracy: 0.8223 - val_loss: 0.4109 - val_accuracy: 0.8033\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8264 - val_loss: 0.4057 - val_accuracy: 0.8033\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3972 - accuracy: 0.8388 - val_loss: 0.4018 - val_accuracy: 0.8033\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.7975 - val_loss: 0.3978 - val_accuracy: 0.8033\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3928 - accuracy: 0.8140 - val_loss: 0.3939 - val_accuracy: 0.8033\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8471 - val_loss: 0.3909 - val_accuracy: 0.8033\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8512 - val_loss: 0.3881 - val_accuracy: 0.8033\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8554 - val_loss: 0.3863 - val_accuracy: 0.8033\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8430 - val_loss: 0.3855 - val_accuracy: 0.7869\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8306 - val_loss: 0.3854 - val_accuracy: 0.8033\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3494 - accuracy: 0.8471 - val_loss: 0.3850 - val_accuracy: 0.8033\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8554 - val_loss: 0.3842 - val_accuracy: 0.8033\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8843 - val_loss: 0.3838 - val_accuracy: 0.8033\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8347 - val_loss: 0.3844 - val_accuracy: 0.8361\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3214 - accuracy: 0.8512 - val_loss: 0.3847 - val_accuracy: 0.8361\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3435 - accuracy: 0.8678 - val_loss: 0.3836 - val_accuracy: 0.8361\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.8884 - val_loss: 0.3832 - val_accuracy: 0.8361\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8719 - val_loss: 0.3835 - val_accuracy: 0.8361\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8554 - val_loss: 0.3827 - val_accuracy: 0.8361\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3018 - accuracy: 0.8760 - val_loss: 0.3836 - val_accuracy: 0.8361\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3268 - accuracy: 0.8719 - val_loss: 0.3847 - val_accuracy: 0.8361\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8636 - val_loss: 0.3854 - val_accuracy: 0.8361\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3249 - accuracy: 0.8554 - val_loss: 0.3859 - val_accuracy: 0.8361\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.8595 - val_loss: 0.3856 - val_accuracy: 0.8361\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3273 - accuracy: 0.8471 - val_loss: 0.3859 - val_accuracy: 0.8361\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.8884 - val_loss: 0.3868 - val_accuracy: 0.8361\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2901 - accuracy: 0.8678 - val_loss: 0.3874 - val_accuracy: 0.8361\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2839 - accuracy: 0.9008 - val_loss: 0.3881 - val_accuracy: 0.8361\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8884 - val_loss: 0.3886 - val_accuracy: 0.8361\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2806 - accuracy: 0.8884 - val_loss: 0.3895 - val_accuracy: 0.8197\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8678 - val_loss: 0.3900 - val_accuracy: 0.8197\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8884 - val_loss: 0.3906 - val_accuracy: 0.8033\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 2ms/step - loss: 0.2882 - accuracy: 0.8843 - val_loss: 0.3903 - val_accuracy: 0.8033\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2904 - accuracy: 0.8802 - val_loss: 0.3897 - val_accuracy: 0.8033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x171f7c70730>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c173919f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
